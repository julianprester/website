---
title: '100M Token Context Windows'
url: https://magic.dev/blog/100m-token-context-windows
date: 2024-09-28
thumbnail: https://magic.dev/blog/100m-token-context-windows/hero.png
tags:
  - links
---

Magic claims to have built a 100M token context model that's 1000x cheaper than Llama at the same context length.  However, their evaluation method (HashHop) is questionable and the provided examples of code generation are underwhelming for a model of this supposed scale.
