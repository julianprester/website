---
title: Brute-forcing the LLM guardrails
url: 'https://medium.com/@volkot/brute-forcing-the-llm-guardrails-e02fcd9bc9a4'
date: '2024-11-03T21:16:31.188Z'
thumbnail: 'https://miro.medium.com/v2/da:true/resize:fit:874/0*1M9ZZzJSO7Q6t2c4'
syndicated: false
scheduled: 2024-12-08T03:00:00.000Z
---
LLM guardrails are surprisingly easy to bypass. Brute-forcing prompts on Google Gemini shows a 60% success rate in getting medical interpretations from X-rays, despite safety measures.  Context similarity between prompt and desired response weakens guardrails significantly.
