---
title: GPTs and Hallucination
url: 'https://queue.acm.org/detail.cfm?id=3688007'
date: 2024-09-26T00:00:00.000Z
thumbnail: 'https://queue.acm.org/img/icon_pdf.png'
syndicated: false
tags:
  - links
scheduled: 2024-11-03T03:00:00.000Z
---

LLMs are basically crowdsourced knowledge, good for common topics but hallucinate on niche ones. They reflect dominant discourse, not necessarily truth. Worrying given our increasing reliance on them for information.
