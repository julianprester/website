---
title: 'GPTs and Hallucination'
url: https://queue.acm.org/detail.cfm?id=3688007
date: 2024-09-26
thumbnail: https://queue.acm.org/img/icon_pdf.png
tags:
  - links
---

LLMs are basically crowdsourced knowledge, good for common topics but hallucinate on niche ones. They reflect dominant discourse, not necessarily truth. Worrying given our increasing reliance on them for information.
